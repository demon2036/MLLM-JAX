backend: tpu
base_model: Qwen/Qwen2.5-1.5B-Instruct
output_dir: runs/sid_sft_jax_smoke_qwen25_1p5b_instruct_industrial_tpu
seed: 42
device: tpu

jax:
  # Use only DP on v4-8 to avoid sharding embeddings by vocab.
  mesh_shape: "dp:-1,fsdp:1,tp:1"
  param_dtype: float32
  compute_dtype: bfloat16
  max_cache_length: 2048

data:
  category: Industrial_and_Scientific
  train_file: workdir/MiniOneRec/data/Amazon/train/Industrial_and_Scientific_5_2016-10-2018-11.csv
  eval_file: workdir/MiniOneRec/data/Amazon/valid/Industrial_and_Scientific_5_2016-10-2018-11.csv
  test_file: workdir/MiniOneRec/data/Amazon/test/Industrial_and_Scientific_5_2016-10-2018-11.csv
  info_file: workdir/MiniOneRec/data/Amazon/info/Industrial_and_Scientific_5_2016-10-2018-11.txt
  sid_index_path: workdir/MiniOneRec/data/Amazon/index/Industrial_and_Scientific.index.json
  item_meta_path: workdir/MiniOneRec/data/Amazon/index/Industrial_and_Scientific.item.json
  max_len: 256
  sample_train: 256
  sample_eval: 128
  sample_test: 128

tasks:
  sid_next_item: true
  sid_item_alignment: true
  fusion_seq_rec: true

train:
  # JAX backend interprets this as the micro-batch per (dp*fsdp) replica.
  # Effective batch size = micro_batch * (dp*fsdp) * gradient_accumulation_steps.
  # With v4-8 default (4 local devices), micro=8 and accum=32 => effective_bs=1024.
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 32
  learning_rate: 0.0003
  optimizer: adamw
  weight_decay: 0.0
  num_train_epochs: 1
  max_steps: 2
  warmup_steps: 0
  logging_steps: 1
  eval_steps: 0
  save_steps: 0
  save_total_limit: 1
  group_by_length: false
  freeze_LLM: false
  train_from_scratch: false
  resume_from_checkpoint: null
  early_stopping_patience: 0
  bf16: false
  fp16: false

eval:
  enabled: true
  batch_size: 1
  num_beams: 10
  max_new_tokens: 32
  length_penalty: 0.0
  topk: [1, 3, 5, 10]
  constrained: true
  save_predictions_json: true

wandb:
  project: minionerec-sid-sft
  mode: online
  name: null

