# GRPO/GSM8K config: set rollout `batch_size=32` (sequences per training step, global)
# and `max_length_sample=1024` for timing experiments.
#
# Derived from: `plugins/training/configs/grpo_gsm8k_default.yaml`
# Notes:
# - For TPU runs, keep secrets (WANDB_API_KEY) in `/root/.env` (not committed).
# - This config is meant for throughput / scaling experiments.

model_path: Qwen/Qwen2.5-7B-Instruct

steps: 20

rollout:
  backend: naive
  batch_size: 32
  batch_size_per_process: null
  batch_size_per_device: null
  prompts_per_pass_per_process: null
  prompts_per_pass_per_device: null
  n: 1
  global_length: 512
  max_length_sample: 1024

train:
  # Micro-batch the update step to reduce peak memory with large rollout batches.
  global_micro_batch_size: null
  micro_batch_size_per_process: 4
  micro_batch_size_per_device: null
  ppo_epochs: 1
  beta: 0.0

mesh_shape: 1,-1,1

wandb_project: mllm-jax-grpo-gsm8k
wandb_name: null

reward_weights: [1.0, 0.5, 0.5]

eval_every_steps: 0
eval_batches_per_process: 1
eval_split: test
