# GRPO/GSM8K benchmark config (Qwen2.5-3B-Instruct)
#
# Purpose: timing-focused run with *prompt* batch size 128 on v6e-16 (multi-host).
#
# Naming note:
# - `pbs128` means `rollout.batch_size: 128` global PROMPTS per step.
# - With `rollout.n: 8`, this is 1024 sequences/step globally, so we split rollout into passes.
#
# Notes:
# - v6e-16 is 4-host multi-host (jax.process_count=4). Always launch with `--worker=all`.
# - `mesh_shape: auto` resolves to full-device FSDP (`1,-1,1`) in this repo, which was
#   measured to be faster for this decode-dominated GRPO workload than host-local sharding.
# - Eval is disabled to avoid timing spikes.

model_path: Qwen/Qwen2.5-3B-Instruct

steps: 12

rollout:
  backend: naive
  batch_size: 128
  max_prompts_per_pass_per_process: 16
  fast_generate: true
  fast_qwen2_decode_attention: true
  n: 8
  global_length: 512
  max_length_sample: 1024

train:
  micro_batch_size: null
  micro_batch_size_per_device: 4
  ppo_epochs: 1
  beta: 0.0

mesh_shape: auto

wandb_project: mllm-jax-grpo-gsm8k-pbs128-v6e-bench
wandb_mode: online
wandb_name: grpo_gsm8k_qwen25_3b_pbs128_steps12_v6e16_bench

reward_weights: [1.0, 0.5, 0.5]

eval_every_steps: 0
eval_batches_per_process: 1
eval_split: test
