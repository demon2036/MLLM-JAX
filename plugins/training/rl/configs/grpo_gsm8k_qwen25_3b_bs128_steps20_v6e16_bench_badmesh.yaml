# GRPO/GSM8K benchmark config (Qwen2.5-3B-Instruct)
#
# Purpose: reproduce the common v6e-16 slowdown when `fsdp` spans hosts.
#
# WARNING:
# - `mesh_shape: 1,-1,1` becomes `dp=1, fsdp=16, tp=1` on v6e-16 and can be much
#   slower for decode-heavy rollouts due to cross-host collectives.

model_path: Qwen/Qwen2.5-3B-Instruct

steps: 20

rollout:
  backend: naive
  batch_size: 16
  n: 8
  global_length: 512
  max_length_sample: 1024

train:
  micro_batch_size: null
  micro_batch_size_per_device: 4
  ppo_epochs: 1
  beta: 0.0

mesh_shape: 1,-1,1

wandb_project: mllm-jax-grpo-gsm8k
wandb_mode: online
wandb_name: grpo_gsm8k_qwen25_3b_bs128_steps20_v6e16_badmesh

reward_weights: [1.0, 0.5, 0.5]

eval_every_steps: 0
eval_batches_per_process: 1
eval_split: test

